<h2 align="center">
  Awesome-What-Bimanual-Can-Do
</h2>

<p align="center">
  <img src="assets/img/wbcd_logo_wide.png" alt="WBCD Logo" width="100%">
</p>

<h5 align="center">

[![arXiv](https://img.shields.io/badge/arXiv-coming_soon-b31b1b.svg?logo=arXiv)](https://arxiv.org/) 
[![Home Page](https://img.shields.io/badge/Project-Website-green.svg)](https://wbcdcompetition.github.io/)
[![X](https://img.shields.io/badge/@WBCDCompetition-black?logo=X)](https://x.com/WBCDCompetition) 

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
![visitors](https://visitor-badge.laobi.icu/badge?page_id=xzxzxzxz.wbcd)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) 
[![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) 
[![GitHub license](https://badgen.net/github/license/Naereen/Strapdown.js)](https://github.com/Naereen/StrapDown.js/blob/master/LICENSE)

<strong>Media Coverage (Chinese): <a href="https://mp.weixin.qq.com/s/SqlE_TpMyzCj3Us1R3L4NA">甲子光年</a> | <a href="https://mp.weixin.qq.com/s/GwJiwAKvZb0K-uHy2_rzBQ">36氪</a> | <a href="https://mp.weixin.qq.com/s/H26K-brCRXqNVZ-BScoC-g">机器之心</a> | <a href="https://mp.weixin.qq.com/s/Y-9wZm2Rwr_gLEelUgV39A">量子位</a></strong>

<!-- <strong>Sponsers Highlight: <a href="https://">Galaxea 星海图</a>(Track#1) | <a href="https://">AgileX 松灵机器人</a>(Track#2) | <a href="https://">ARX 方舟无限</a>(Track#3)</strong> -->

</h5>

<p align="center"> </p>

> 😎 A curated list of research, news, datasets, benchmarks, hardware systems, challenges/competitions and real-world applications in **Bimanual Manipulation and Learning from Demonstrations** — affiliated with the ICRA 2025 What Bimanual Teleoperation and Learning from Demonstration Can Do (WBCD) Today Competition, founded by [Dr. Zhuo Xu](https://drzhuoxu.github.io/). Stay tuned as this list evolves alongside the upcoming technical survey, which will include taxonomy, insights, and contributions within recent 5 years and our lessons learned from WBCD competition.

> 📣 **Disclaimer:** The paper release timestamps and acceptance status are primarily based on the comment section on arXiv. We will continue to verify and update this information. If you are the author of a paper, feel free to open an issue to help us keep things up to date! 

> 📣 **Call of PRs!** Think we missed your awesome paper or work? You're very welcome to open a pull request with the title and link — we'll review and update after checking the scope!

<h3>Table of Contents</h3>

<ul>
  <li><a href="#vision">0. Our Vision</a></li>
  <li><a href="#news">1. News</a></li>
  <li><a href="#events">2. Events</a></li>
  <li><a href="#related-surveys">3. Related Surveys</a></li>
  <li><a href="#wbcd-technical">4. WBCD - Technical Paper List</a><br/></li>
  <li><a href="#wbcd-datasetbenchmark">5. WBCD - Dataset & Benchmark</a><br/></li>
  <li><a href="#wbcd-simulator">6. WBCD - Simulator</a><br/></li>
  <li><a href="#wbcd-hardware">7. WBCD - Hardware</a><br/></li>
  <li><a href="#wbcd-datacollection">8. WBCD - Data Collection Solution</a><br/></li></ul>

<hr/>

<h2 id="vision">😶‍🌫️ 0. Our Vision</h2>
<p>
  <strong>🚧 TODO:</strong> Edit our vision.
</p>

<hr/>

<h2 id="news">🔥 1. News</h2>
<p>
  <strong>🚧 TODO:</strong> Edit news.
</p>

<hr/>

<h2 id="events">🎟️ 2. Events</h2>
<p>
  <strong>🚧 TODO:</strong> Edit challenges and workshops.
</p>

<ul>
  <li>
    <strong><a href="https://2025.ieee-icra.org/competitions/#wbcd">The 1st What Bimanual Teleoperation and Learning from Demonstration Can Do (WBCD)</a></strong><br/>
    <code><em>🏆 Challenge</em></code> <code><em>ICRA 2025, Atlanta, USA</em></code> | <a href="https://wbcdcompetition.github.io/">Website</a><br/>
  </li>
</ul>

<ul>
  <li>
    <strong><a href="https://">The 1st What Bimanual Teleoperation and Learning from Demonstration Can Do (WBCD)</a></strong><br/>
    <code><em>🥂 Workshop</em></code> <code><em>TBD 2025</em></code> | <a href="https://wbcdcompetition.github.io/">Website</a><br/>
  </li>
</ul>

<ul>
  <li>
    <strong><a href="https://">The 2nd What Bimanual Teleoperation and Learning from Demonstration Can Do (WBCD)</a></strong><br/>
    <code><em>🏆 Challenge</em></code> <code><em>TBD 2025</em></code> | <a href="https://wbcdcompetition.github.io/">Website</a><br/>
  </li>
</ul>

<hr/>

<h2 id="related-surveys">🗃 3. Related Surveys</h2>
<p>
  <strong>🚧 TODO:</strong> Edit related surveys.
</p>



<hr/>

<h2 id="wbcd-technical">📑 4. WBCD - Technical Paper List</h2>
<p>
  Includes accepted and arXiv technical papers on bimanual manipulation.<br/>
  <strong>🚧 TODO:</strong> Currently listed in reverse chronological order by year; further categorization by algorithmic approach and end-effector type is in progress.
</p>

<h4>2025</h4>
<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2506.07339">Real-Time Execution of Action Chunking Flow Policies</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>06/2025</em></code> | <a href="https://www.pi.website/research/real_time_chunking">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2506.06221">BiAssemble: Learning Collaborative Affordance for Bimanual Geometric Assembly</a></strong><br/>
    <code><em>ICML 2025</em></code> <code><em>06/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2506.06196">Bridging Perception and Action: Spatially-Grounded Mid-Level Representations for Robot Generalization</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>06/2025</em></code> | <a href="https://www.pi.website/research/real_time_chunking">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2506.04147">SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>06/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.24853">DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.24819">Bi-Manual Joint Camera Calibration and Scene Representation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.24156">Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.13667">Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.13441">GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.12748">TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.11032">DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.07819">H3DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.05287">Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.04860">D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>05/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2505.06111">UniVLA: Learning to Act Anywhere with Task-centric Latent Actions</a></strong><br/>
    <code><em>RSS 2025</em></code> <code><em>05/2025</em></code> | <a href="https://github.com/OpenDriveLab/UniVLA">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://www.pi.website/blog/pi05">π-0.5: a Vision-Language-Action Model with Open-World Generalization</a></strong><br/>
    <code><em>Physical Intelligence</em></code> <code><em>04/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2504.18904">ROBOVERSE: Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning</a></strong><br/>
    <code><em>RSS 2025</em></code> <code><em>04/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2504.17784">Gripper Keypose and Object Pointflow as Interfaces for Bimanual Robotic Manipulation</a></strong><br/>
    <code><em>RSS 2025</em></code> <code><em>04/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2504.13059">RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins</a></strong><br/>
    <code><em>CVPR 2025</em></code> <code><em>04/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.20020">Gemini Robotics: Bringing AI into the Physical World</a></strong><br/>
    <code><em>Google Deepmind</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.23271">Learning Coordinated Bimanual Manipulation Policies using State Diffusion and Inverse Dynamics Models</a></strong><br/>
    <code><em>ICRA 2025</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.21860">ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning</a></strong><br/>
    <code><em>CVPR 2025</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.12466">Modality-Composable Diffusion Policy via Inference-Time Distribution-level Composition</a></strong><br/>
    <code><em>ICLR 2025 WS</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.10631">HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://hybrid-vla.github.io/">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.09186">Rethinking Bimanual Robotic Manipulation: Learning with Decoupled Interaction Framework</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.14734">GR00T N1: An Open Foundation Model for Generalist Humanoid Robots</a></strong><br/>
    <code><em>NVIDIA</em></code> <code><em>03/2025</em></code> | <a href="https://developer.nvidia.com/isaac/gr00t">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.13916">Learning Bimanual Manipulation via Action Chunking and Inter-Arm Coordination with Transformers</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.12725">Humanoids in Hospitals: A Technical Study of Humanoid Surrogates for Dexterous Medical Interventions</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.10743">Spatial-Temporal Graph Diffusion Policy with Kinematic Modeling for Bimanual Robotic Manipulation</a></strong><br/>
    <code><em>CVPR 2025</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.10070">AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for Embodied AI</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.09186">Rethinking Bimanual Robotic Manipulation: Learning with Decoupled Interaction Framework</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.07963">Hierarchical Contact-Rich Trajectory Optimization for Multi-Modal Manipulation using Tight Convex Relaxations</a></strong><br/>
    <code><em>ICRA 2025</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.05817">GraphGarment: Learning Garment Dynamics for Bimanual Cloth Manipulation Tasks</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2503.05652">BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>03/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2502.16932">DemoGen: Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>02/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2502.16908">A low-cost and lightweight 6 DoF bimanual arm for dynamic and contact-rich manipulation</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>02/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2502.19645">Fine-tuning vision-language-action models: Optimizing speed and success</a></strong><br/>
    <code><em>RSS 2025</em></code> <code><em>02/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/2502.19417">Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models </a></strong><br/>
    <code><em>Physical Intelligence</em></code> <code><em>02/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
  <li>
    <strong><a href="https://arxiv.org/abs/">Paper_Title</a></strong><br/>
    <code><em>arXiv</em></code> <code><em>xx/2025</em></code> | <a href="https://">Website</a><br/>
  </li>
</ul>

<h4>2024</h4>
<!-- <ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul> -->

<h4>2023</h4>
<!-- <ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul> -->

<h4>2022</h4>
<!-- <ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul> -->

<h4>2021</h4>
<!-- <ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul> -->

<hr/>

<h2 id="wbcd-datasetbenchmark">📊 5. WBCD - Dataset & Benchmark</h2>
<p>
  Includes existing datasets and benchmarks that support bimanual manipulation.<br/>
  <strong>🚧 TODO:</strong> Currently listed in reverse chronological order by year; further categorization is in progress.
</p>

<h4>2025</h4>
<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<h4>2024</h4>
<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<h4>2023</h4>
<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<h4>2022</h4>
<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<h4>2021</h4>
<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<hr/>

<h2 id="wbcd-simulator">🧪 6. WBCD - Simulator</h2>
<p>
  Includes simulators that support the design, generation, and import of bimanual manipulation tasks.<br/>
  <strong>🚧 TODO:</strong> Currently listed in reverse chronological order by year.
</p>

<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<hr/>

<h2 id="wbcd-hardware">🤖 7. WBCD - Hardware</h2>
<p>
  Includes hardware systems designed for bimanual manipulation tasks.<br/>
  <strong>🚧 TODO:</strong> Currently listed in reverse chronological order by year; further classification into lab prototypes vs. commercial/industrial products is in progress.
</p>

<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>

<hr/>

<h2 id="wbcd-datacollection">🕹️ 8. WBCD - Data Collection Solution</h2>
<p>
  Includes various data collection setups and methods for bimanual manipulation tasks.<br/>
  <strong>🚧 TODO:</strong> TBD
</p>

<ul>
  <li>
    <strong><a href="https://arxiv.org/abs/2401.12345">Dexterous Dual-Arm Manipulation via Demonstration-Augmented Reinforcement Learning</a></strong><br/>
    <code><em>ICRA 2025</em></code> | <a href="https://arxiv.org/abs/2401.12345">Website</a><br/>
  </li>
</ul>